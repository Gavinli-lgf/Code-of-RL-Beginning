{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4ab64a-c1b6-4247-bb4b-9c72ebf63778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     #只需要下载numpy库即可\n",
    "import random\n",
    "import GridWorld_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad418bf1-1806-4c6d-830a-498b9c371405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️🚫🚫⬜️⬜️\n",
      "⬜️⬜️🚫⬜️⬜️\n",
      "⬜️🚫✅🚫⬜️\n",
      "⬜️🚫⬜️⬜️⬜️\n",
      "➡️⬇️➡️⬇️🔄\n",
      "⬆️🔄⏬⬇️🔄\n",
      "⬆️➡️⏩️⬇️⬆️\n",
      "➡️🔄✅🔄➡️\n",
      "➡️⏪➡️⬅️⬆️\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9   #折扣因子，越接近0越近视\n",
    "\n",
    "rows = 5      #记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(rows=rows, columns=columns, forbiddenAreaNums=8, targetNums=2, seed = 52,forbiddenAreaScore=-10)\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\".#\",\".T\"])             #赵老师4-1的例子\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\"##.T\",\"...#\",\"....\"])  #随便弄的例子\n",
    "gridworld = GridWorld_v2.GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]) \n",
    "#gridworld = GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\"T.\"]) \n",
    "gridworld.show()\n",
    "\n",
    "\n",
    "value = np.zeros(rows*columns)       #初始化可以任意，也可以全0\n",
    "qtable = np.zeros((rows*columns,5))  #初始化，这里主要是初始化维数，里面的内容会被覆盖所以无所谓\n",
    "\n",
    "# np.random.seed(50)\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.showPolicy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f0be645-73c7-44ef-a92c-d57879825e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.99\n",
    "p1 = 1-epsilon * (4/5)\n",
    "p2 = epsilon/5\n",
    "d = {1:p1, 0:p2}\n",
    "a2 = np.vectorize(d.get)(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a97f3b-25a4-4071-be6d-92b8b4f541c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a61507-1f32-4431-aa4b-7e3b3c5825e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[-0.50927475 -0.14070731 -0.14324995 -0.38438712 -0.1530971 ]\n",
      " [-0.03856409 -0.53091662 -0.21396443 -0.10593053 -0.18790431]\n",
      " [-0.03852397 -0.14134947 -0.19588346 -0.0940211  -0.09507617]\n",
      " [-0.04846244 -0.59073003 -0.30240289 -0.28572883 -0.16706666]\n",
      " [-0.04855244 -0.49212653 -0.49516866 -0.15633104 -0.14907693]]\n",
      "➡️➡️➡️➡️⬇️\n",
      "⬆️⏫️⏫️⬆️⬆️\n",
      "⬆️⬅️⏬⬆️⬆️\n",
      "⬆️⏩️✅⏪⬆️\n",
      "⬆️⏩️⬆️➡️⬆️\n",
      "-0.22833987322135776\n",
      "trajectorySteps 20000\n",
      "epision:0.21799999999999975, p1:0.8256000000000002, p0:0.04359999999999995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m j \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     34\u001b[0m cnt \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m)]\n\u001b[1;32m---> 36\u001b[0m Trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mgridworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrajectoryScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnowState\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_epsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectorySteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_when_reach_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(Trajectory)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\RL\\GridWorld_v2.py:95\u001b[0m, in \u001b[0;36mGridWorld_v2.getTrajectoryScore\u001b[1;34m(self, nowState, action, policy, steps, stop_when_reach_target)\u001b[0m\n\u001b[0;32m     92\u001b[0m nowAction \u001b[38;5;241m=\u001b[39m nextAction\n\u001b[0;32m     94\u001b[0m score, nextState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetScore(nowState, nowAction)\n\u001b[1;32m---> 95\u001b[0m nextAction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnextState\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     97\u001b[0m res\u001b[38;5;241m.\u001b[39mappend((nowState, nowAction, score, nextState, nextAction))\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (stop_when_reach_target):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# print(nextState)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# print(self.scoreMap)\u001b[39;00m\n",
      "File \u001b[1;32mmtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mcumsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#通过采样的方法计算action value，model free的话意味着不知道整个gridworld的概率了，所以不能直接套贝尔曼方程迭代求解\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.show()\n",
    "gridworld.showPolicy(policy)\n",
    "print(\"random policy\")\n",
    "\n",
    "\n",
    "trajectorySteps = 20000\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.5\n",
    "# qtable = np.zeros((rows*columns,5))    #生成Qtable，也就是action-value-table\n",
    "state_value = np.zeros((rows * columns))\n",
    "\n",
    "num_episodes = 6000\n",
    "for episode in range(num_episodes):\n",
    "    # \n",
    "    if(epsilon > 0.001) :\n",
    "        epsilon -= 0.001\n",
    "    else:\n",
    "        epsilon = 0.001\n",
    "        \n",
    "    p1 = 1-epsilon * (4/5)\n",
    "    p0 = epsilon/5\n",
    "    # trajectorySteps = int(20+epsilon*1000)\n",
    "    print(\"trajectorySteps\",trajectorySteps)\n",
    "    print(f\"epision:{epsilon}, p1:{p1}, p0:{p0}\")\n",
    "    \n",
    "    d = {1:p1, 0:p0}\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "    \n",
    "    i = random.randint(0,24)  #初始状态\n",
    "    j = random.randint(0,4)\n",
    "    \n",
    "    cnt = [0 for i in range(25)]\n",
    "    \n",
    "    Trajectory = gridworld.getTrajectoryScore(nowState=i, action=j, policy=policy_epsilon, steps=trajectorySteps, stop_when_reach_target=True)\n",
    "    if(len(Trajectory)>5000):\n",
    "        continue\n",
    "    clear_output(wait=True)\n",
    "    # 注意这里的返回值是大小为(trajectorySteps+1)的元组列表，因为把第一个动作也加入进去了\n",
    "    steps = len(Trajectory) - 1\n",
    "    for k in range(steps,-1,-1):\n",
    "        tmpstate, tmpaction, tmpscore, nextState, nextAction  = Trajectory[k]\n",
    "        cnt[tmpstate] += 1\n",
    "        TD_error = state_value[tmpstate] - (tmpscore + gamma * state_value[nextState])\n",
    "        state_value[nextState] = state_value[tmpstate] - learning_rate * TD_error\n",
    "    print(np.array(cnt).reshape(5,5))\n",
    "    for i in range(rows * columns):\n",
    "        for j in range(5):\n",
    "            score,nextState = gridworld.getScore(i,j) \n",
    "            qtable[i][j] = score + gamma * value[nextState]\n",
    "    \n",
    "    print(state_value.reshape(5,5))\n",
    "    gridworld.showPolicy(policy)\n",
    "    print(np.array(state_value).mean())\n",
    "    \n",
    "    \n",
    "    policy = np.eye(5)[np.argmax(qtable,axis=1)]  #qtable的最优值作为更新策略，并用独热码来表示\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "        \n",
    "    # print(np.array(cnt).reshape(5,5))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f5403-06f9-499a-b0c8-e628b4b78365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
