{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843482d8-4944-4de7-9ea1-62a089cb0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     #只需要下载numpy库即可\n",
    "import random\n",
    "import GridWorld_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864c3b7f-fea4-4caa-8ae5-dce3516b4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬜️⬜️⬜️⬜️⬜️\n",
      "⬜️🚫🚫⬜️⬜️\n",
      "⬜️⬜️🚫⬜️⬜️\n",
      "⬜️🚫✅🚫⬜️\n",
      "⬜️🚫⬜️⬜️⬜️\n",
      "🔄⬇️➡️⬆️⬅️\n",
      "⬅️⏬⏬⬅️⬅️\n",
      "⬅️⬅️⏫️⬇️⬅️\n",
      "⬅️⏫️✅⏩️⬆️\n",
      "➡️⏬⬅️⬆️⬆️\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9   #折扣因子，越接近0越近视\n",
    "\n",
    "rows = 5      #记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(rows=rows, columns=columns, forbiddenAreaNums=8, targetNums=2, seed = 52,forbiddenAreaScore=-10)\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\".#\",\".T\"])             #赵老师4-1的例子\n",
    "# gridworld = GridWorld_v2.GridWorld_v2(desc = [\"##.T\",\"...#\",\"....\"])  #随便弄的例子\n",
    "gridworld = GridWorld_v2.GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]) \n",
    "#gridworld = GridWorld_v2(forbiddenAreaScore=-10, score=1,desc = [\"T.\"]) \n",
    "gridworld.show()\n",
    "\n",
    "\n",
    "value = np.zeros(rows*columns)       #初始化可以任意，也可以全0\n",
    "qtable = np.zeros((rows*columns,5))  #初始化，这里主要是初始化维数，里面的内容会被覆盖所以无所谓\n",
    "\n",
    "# np.random.seed(50)\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.showPolicy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e69a30-8d69-4f7b-8b2b-51cbee15346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.9\n",
    "p1 = 1-epsilon * (4/5)\n",
    "p2 = epsilon/5\n",
    "d = {1:p1, 0:p2}\n",
    "a2 = np.vectorize(d.get)(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83befbda-7855-44ca-b31f-47cf5a074cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f4237-0058-4867-b40a-788fed400c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3689097d-fac9-45af-aa1a-a883eff8837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.43386866e+00  3.81365096e+00  4.23756037e+00  4.78238193e+00\n",
      "   5.31252381e+00]\n",
      " [ 3.08852830e+00  2.81889686e+00  4.77571747e+00  5.23048539e+00\n",
      "   5.81565784e+00]\n",
      " [ 2.78054139e+00 -2.52712050e-03  9.98962000e+00  5.75521354e+00\n",
      "   6.46174258e+00]\n",
      " [ 2.53943139e+00  9.99155336e+00  9.92790438e+00  9.99438968e+00\n",
      "   7.28757338e+00]\n",
      " [-7.82057473e-04  8.99364000e+00  9.99322139e+00  8.99547800e+00\n",
      "   8.09734767e+00]]\n",
      "➡️➡️➡️➡️⬇️\n",
      "⬆️⏪⏩️➡️⬇️\n",
      "⬆️⬅️⏬➡️⬇️\n",
      "⬆️⏩️✅⏪⬇️\n",
      "⬆️⏩️⬆️⬅️⬅️\n",
      "5.76454476613946\n",
      "trajectorySteps 20000\n",
      "epision:0.001, p1:0.9992, p0:0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m qtable_rewards \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows \u001b[38;5;241m*\u001b[39m columns)] \n\u001b[0;32m     34\u001b[0m qtable_nums \u001b[38;5;241m=\u001b[39m    [[\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rows \u001b[38;5;241m*\u001b[39m columns)]\n\u001b[1;32m---> 35\u001b[0m Trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mgridworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrajectoryScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnowState\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_epsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectorySteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 注意这里的返回值是大小为(trajectorySteps+1)的元组列表，因为把第一个动作也加入进去了\u001b[39;00m\n",
      "File \u001b[1;32m~\\RL\\GridWorld_v2.py:91\u001b[0m, in \u001b[0;36mGridWorld_v2.getTrajectoryScore\u001b[1;34m(self, nowState, action, policy, steps)\u001b[0m\n\u001b[0;32m     88\u001b[0m     nowAction \u001b[38;5;241m=\u001b[39m nextAction\n\u001b[0;32m     90\u001b[0m     score, nextState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetScore(nowState, nowAction)\n\u001b[1;32m---> 91\u001b[0m     nextAction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnextState\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     93\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend((nowState, nowAction, score, nextState, nextAction))\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#通过采样的方法计算action value，model free的话意味着不知道整个gridworld的概率了，所以不能直接套贝尔曼方程迭代求解\n",
    "policy = np.eye(5)[np.random.randint(0,5,size=(rows*columns))] \n",
    "gridworld.show()\n",
    "gridworld.showPolicy(policy)\n",
    "print(\"random policy\")\n",
    "\n",
    "\n",
    "trajectorySteps = 20000\n",
    "epsilon = 0.2\n",
    "qtable = np.zeros((rows*columns,5))    #生成Qtable，也就是action-value-table\n",
    "\n",
    "num_episodes = 6000\n",
    "for episode in range(num_episodes):\n",
    "    # \n",
    "    if(epsilon > 0.001) :\n",
    "        epsilon -= 0.001\n",
    "    else:\n",
    "        epsilon = 0.001\n",
    "        \n",
    "    p1 = 1-epsilon * (4/5)\n",
    "    p0 = epsilon/5\n",
    "    # trajectorySteps = int(20+epsilon*1000)\n",
    "    print(\"trajectorySteps\",trajectorySteps)\n",
    "    print(f\"epision:{epsilon}, p1:{p1}, p0:{p0}\")\n",
    "    \n",
    "    d = {1:p1, 0:p0}\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "    \n",
    "    i = random.randint(0,24)  #初始状态\n",
    "    j = random.randint(0,4)\n",
    "\n",
    "    cnt = [0 for i in range(25)]\n",
    "    qtable_rewards = [[0 for j in range(5)] for i in range(rows * columns)] \n",
    "    qtable_nums =    [[0 for j in range(5)] for i in range(rows * columns)]\n",
    "    Trajectory = gridworld.getTrajectoryScore(nowState=i, action=j, policy=policy_epsilon, steps=trajectorySteps)\n",
    "    clear_output(wait=True)\n",
    "    # 注意这里的返回值是大小为(trajectorySteps+1)的元组列表，因为把第一个动作也加入进去了\n",
    "    score = 0\n",
    "    for k in range(trajectorySteps,-1,-1):\n",
    "        tmpstate, tmpaction, tmpscore, _, __  = Trajectory[k]\n",
    "        cnt[tmpstate] += 1\n",
    "        score = score*gamma + tmpscore  #细节从后往前优化算法\n",
    "        \n",
    "        qtable_rewards[tmpstate][tmpaction] += score\n",
    "        qtable_nums[tmpstate][tmpaction] += 1\n",
    "        qtable[tmpstate][tmpaction] = qtable_rewards[tmpstate][tmpaction] / qtable_nums[tmpstate][tmpaction]\n",
    "\n",
    "    values = []\n",
    "    for i in range(25):\n",
    "        v = 0\n",
    "        for j in range(5):\n",
    "            v += policy_epsilon[i][j] * qtable[i][j]\n",
    "        values.append(v)\n",
    "    print(np.array(values).reshape(5,5))\n",
    "    \n",
    "    # print(qvalue.reshape(5,5))\n",
    "    gridworld.showPolicy(policy)\n",
    "    print(np.array(values).mean())\n",
    "    \n",
    "    \n",
    "    policy = np.eye(5)[np.argmax(qtable,axis=1)]  #qtable的最优值作为更新策略，并用独热码来表示\n",
    "    policy_epsilon = np.vectorize(d.get)(policy)\n",
    "        \n",
    "    # print(np.array(cnt).reshape(5,5))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1ce49-9b72-44a9-9413-c811bb04f577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
